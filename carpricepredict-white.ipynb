{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nfrom catboost import CatBoostRegressor\nfrom bs4 import BeautifulSoup    \nimport requests ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import f_regression, mutual_info_regression\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PolynomialFeatures\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom pandas import Series\n\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.base import clone\nimport datetime\nfrom datetime import datetime, timedelta\nimport math\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\nfrom pprint import pprint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Часть 1. Парсинг"},{"metadata":{},"cell_type":"markdown","source":"Для начала посмотрим тестовый датасет"},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_TEST   = '../input/sf-dst-car-price-prediction/'\ntest = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим 32 столбца, из них только 6 - числовые.  \nТ.е. у нас преимущественно категориальный датасет.  \nПосмотрим на наиболее типичные значения в разных колонках тестового датасета, чтобы понимать, как строить тренировочный датасет train из того, что напарсим."},{"metadata":{"trusted":true},"cell_type":"code","source":"#for col in test.columns:\n#    if col != 'complectation_dict':\n#        print(f'name of column: {col}','\\n', test[col].value_counts()[:10], '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для подготовки к парсингу создадим словарь brand_dict, где ключи - марки автомобилей, а значения - их кол-ва в test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"brands = test.brand.value_counts()\nbrand_dict = {brands.index[i]: brands[i] for i in range(len(brands))}\nbrand_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Сделаем парсинг сайта авто.ру следующим образом:  \n берем фильтр по Москве легковые с пробегом  \n берем фильтр по марке автомобиля из словаря brand_dict, другие марки не трогаем  \n т.к. на каждой странице сайта авто.ру 38 объявления, то парсим примерно brand_dict.keys10/38 страниц,   т.е. в 10 раз больше объявлений, чем в test для каждой марки(если найдется столько)  \n не заходим на страницы отдельных объявлений, т.к. не будем использовать инфо о спецоборудованиии и тд,   ограничимся основными данными "},{"metadata":{},"cell_type":"markdown","source":"Ниже приведен основная часть кода для парсинга"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''auto_list_long =[] # здесь соберем список списков(эл-т - список параметров конкретного автомобиля)\nfor brand in ['MERCEDES']:  # марка авто\n    \n    for i in range(1, 1200):     # кол-во страниц для парсинга с авто.ру   \n        response = requests.get(f'https://auto.ru/moskva/cars/{brand}/used/?output_type=list&page={i}')\n        if response.status_code != 200:\n            raise BaseException(\"response code\" + str(response.status_code))\n        response.encoding = 'utf-8'\n        soup = BeautifulSoup(response.text, 'html.parser')\n        page = soup.find_all('div', class_='ListingItem-module__container')  \n        for k in range(len(page)):     # цикл для прохода по объявлениям в одной странице\n            auto_html = page[k].find_all('meta')\n            auto_list = []\n            for i in range(len(auto_html)):   # цикл для обработки отдельного объявления на странице\n                auto_list.append((str(auto_html[i])[15:]).split('\"', 1)[0])\n                \n            # Убираем лишние параметры автомобиля из списка    \n            pos_out = {4,11,12,14,15,19}\n            auto_list_short = []\n            for n in range(len(auto_list)):   # цикл для удаления лишних параметров из объявления\n                if n not in pos_out:\n                    auto_list_short.append(auto_list[n].replace('\\xa0', ' ')) \n        \n            # Считываем пробег(он расположен отдельно от других данных)    \n            all_km = page[k].find('div', class_='ListingItem-module__kmAge')\n            xx = str(all_km)[39:].split('<', 1)[0].replace('\\xa0', ' ')\n            auto_list_short.append(str(xx))    # добавляем пробег\n            auto_list_long.append(auto_list_short)    # добавляем список пар-ров автомобиля в список списков\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Код запускался не из Kaggle.  \nПосле получения списка списков по каждому отдельному бренду он преобразовывался в датафрейм.  \nЗатем 12 датафреймов были склеены в один - искомый train.  \nЗагрузим его и сделаем предобработку, чтобы соотнести полученные признаки с признаками из test "},{"metadata":{},"cell_type":"markdown","source":"# Часть 2. Предобработка данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_TRAIN   = '../input/car-price-train/'\ntrain = pd.read_csv(DIR_TRAIN+'my_csv_export.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим 14 признаков плюс целевая переменная 'price'  \nДля начала приведем в соответствие с test численные столбцы"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Меняем тип переменных на int64 для численных признаков и целевой и убираем пропуски\nnum_f = ['modelDate', 'productionDate', 'numberOfDoors','mileage', 'price']\ntrain['mileage'] = train['mileage'].apply(lambda x: int(x.replace(' ', '').replace('км', '')))\ntrain.dropna(subset=num_f, inplace=True)\n\nfor col in num_f:\n    train[col] = train[col].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train уменьшился примерно на 6700 строк, в основном - из-за пустых значений в 'price'\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавим в train признак 'vendor', который есть в test\neur = ['BMW', 'VOLKSWAGEN', 'MERCEDES', 'AUDI', 'SKODA', 'VOLVO']\ntrain['vendor'] = train['brand'].apply(lambda x: 'EUROPEAN' if x in eur else 'JAPANESE')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сравнивая test и train, видим, что только признаки 'name' и 'model_name' имеют разные области значений, с остальными все ок"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Признак 'name'\ndisplay(test.name.sample(3), train.name.sample(3)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что признак 'name' - это линейная комбинация других признаков:  \n'name' = 'engineDisplacement' + 'vehicleTransmission' + bool(Allroad) из 'vehicleConfiguration'  \nПонятно, что это категориальный признак и линейная зависимость тут не играет роли, но унифицировать его долго, и это явно не самый важный признак, т.к. его компоненты не теряются.  \nПоэтому не включаем его в итоговый датасет.  \n'Allroad' как особо ценную опцию позже превратим в новый бинарный признак."},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Признак 'model_name'\ndisplay(test.model_name.value_counts()[:3], train.model_name.value_counts()[:3]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что в train этот признак более информативный, но нас интересует короткое название модели,  \nвыделим его"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохраняем исходный вид признаков\ntrain['model_name_long'] =  train['model_name'].copy()\ntest['model_name_long'] =  test['model_name'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вырезаем названия моделей в train и меняем прописные буквы на заглавные \ntrain['model_name'] = train['model_name'].apply(lambda x: (x.split(' ')[1]).upper())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Укорачиваем двойные названия\ntrain['model_name'] = train['model_name'].apply(lambda x: x.split('-')[0])\ntest['model_name'] = test['model_name'].apply(lambda x: x.split('_')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Укорачиваем названия моделей, начинающися с цифры( это надо в основном для 'BMW') \nnum_list = ['0','1','2','3','4','5','6','7','8','9']\ntrain['model_name'] = train['model_name'].apply(lambda x: x[0] if x[0] in num_list else x)\ntest['model_name'] = test['model_name'].apply(lambda x: x[0] if x[0] in num_list else x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проверяем, видим, что совпадение хорошее. Теперь все признаки в train  и test в основном совпадают в областях значений."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(np.sort(test[test.brand == 'MERCEDES'].model_name.unique()),\n        np.sort(train[train.brand == 'MERCEDES'].model_name.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Выбираем признаки для дальнейшей работы  "},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['bodyType', 'brand', 'color', 'fuelType', 'modelDate', 'model_name', 'numberOfDoors',\n           'productionDate', 'vehicleConfiguration', 'vehicleTransmission', 'engineDisplacement',\n           'enginePower', 'mileage', 'vendor']\ncars_train = train[columns]\ncars_test = test[columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Ставим метки 'sample'= 1 or 0 для различения train и test и склеиваем выбранные столбцы.  \n Назовем полученный датасет cars, он будет использоваться для исследовательского анализа признаков(EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_train['sample'] = 1\ncars_test['sample'] = 0\ncars = cars_train.append(cars_test, ignore_index=True, sort=False)\n\n# Целевая переменная\ny = train['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Часть 3. EDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим 14 признаков('sample' не считаем), из них 3 - числовых и 11 - категориальных.  \nСразу заметим, что два категориальных признака - 'enginePower' и 'engineDisplacement' по сути являются числовыми, принимая значения в своих числовых диапазонах. Понятно также то, что цена автомобиля растет в зависимости от роста мощности двигателя или его объема. Поэтому уже на этапе анализа сделаем эти признаки числовыми."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Количество уникальных значений в этих признаках достаточно большое\nprint(cars['enginePower'].nunique(), cars['engineDisplacement'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Избавляемся от пустых значений в 'engineDisplacement'(их всего 101), заменяя на среднее\ncars['engineDisplacement'] = cars['engineDisplacement'].apply(lambda x: '2.5 LTR' if x == ' LTR' else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars['enginePower'] = cars['enginePower'].apply(lambda x: int(x.split(' ')[0].replace('.', '')))\ncars['engineDisplacement'] = cars['engineDisplacement'].apply(\n                                                    lambda x: int(x.split(' ')[0].replace('.', '')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Списки числовых и категориальных признаков в cars\nnum_f = ['modelDate', 'productionDate', 'mileage', 'enginePower', 'engineDisplacement']\ncat_f = ['bodyType', 'brand', 'color', 'fuelType', 'model_name', 'numberOfDoors', 'vehicleConfiguration',\n         'vehicleTransmission', 'vendor']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.1 Числовые признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in num_f:\n    plt.figure()\n    sns.distplot(cars[i])\n    plt.title(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что распределения у признаков близки к нормальным, справа или слева имеются длинные хвосты.  \nПосмотрим на выбросы"},{"metadata":{"trusted":true},"cell_type":"code","source":"def outliers_iqr(x):\n    ''' found outliers '''\n    quartile_1, quartile_3 = np.percentile(x, [25, 75])\n    iqr = quartile_3 - quartile_1\n    lower_bound = quartile_1 - (iqr * 1.5)\n    upper_bound = quartile_3 + (iqr * 1.5)    \n    return np.where((x > upper_bound) | (x < lower_bound))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выведем на экран количество выбросов по межквартильному размаху\nfor i in num_f:\n    print(i, len(outliers_iqr(cars[i])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По межквартильному размаху выбросов оказалось очень много. Имеет смысл ввести эмпирические границы, чтобы отсечь далекие хвосты в данных. Однако это ухудшило оценку и в дальнейшем не использовалось."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим корреляцию числовых признаков\ncorrelation = cars[num_f].corr()\nplt.figure(figsize=(10, 6))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Выводы по рассмотрению корреляции числовых признаков:  \n  +0.97 между годом выпуска и годом модели, видимо, имеет смысл один из этих  признаков убрать или заменить на их разность  \n  +0.84 между мощностью и объемом двигателя  \n  -0.79 между пробегом и годом производства, здесь тоже можно создать новый признак вроде пробег/возраст"},{"metadata":{},"cell_type":"markdown","source":"# 3.2 Категориальные признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_f:\n    print(col, cars[col].nunique(), '\\n', cars[col].value_counts()[:3], '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Зфметим, что признаки 'model_name' и  'vehicleConfiguration' имеют очень большой спектр значений(438 и 650)   \nОстальные 7 категориальных признаков имеют небольшие спектры значений.  \nЗаймемся пока созданием новых признаков, потом продолжим анализ старых и новых вместе. "},{"metadata":{},"cell_type":"markdown","source":"# Часть 4. Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"Создадим два бинарных категориальных признака, которые на практике сильно влияют на стоимость автомобиля:  \n'allroad' - будет отражать наличие полного привода  \n'luxury' - будет отражать премиальность бренда"},{"metadata":{"trusted":true},"cell_type":"code","source":"cars['luxury'] = cars['brand'].apply(lambda x: 1 if x in ['BMW','MERCEDES','LEXUS','INFINITI'] else 0)\ncat_f.append('luxury')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars['allroad'] = cars['vehicleConfiguration'].apply(lambda x: 1 if x.split('_')[0] == 'ALLROAD' else 0)\ncat_f.append('allroad')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из числовых, как и планировали выше, сделаем:  \n    'model_age' - новизна модели на момент производства  \n    'km_pro_year' - cтепень эксплуатации(пробег/год)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cars['model_age'] = cars['productionDate'] - cars['modelDate']\ncars['km_pro_year'] = (cars['mileage']/(2021 - cars['productionDate'])).astype('int64')\nnum_f.append('model_age')\nnum_f.append('km_pro_year')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим их гистограммы, отсекая для наглядности хвосты справа"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.distplot(cars['model_age'][cars['model_age'] < 10])\nplt.title('model_age')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.distplot(cars['km_pro_year'][cars['km_pro_year'] < 35000])\nplt.title('km_pro_year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Снова построим heatmap. Видим, что новые признаки не имеют сильных корреляций\ncorrelation = cars[num_f].corr()\nplt.figure(figsize=(10, 6))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Значимость числовых признаков для целевой по f_regression (линейная зависимость):\nimp_num = Series(f_regression(cars[cars['sample'] == 1][num_f], y)[0], index = num_f)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создадим полиномиальные новые признаки на основе двух числовых 'productionDate' и 'enginePower' и нормируем их"},{"metadata":{"trusted":true},"cell_type":"code","source":"pf = PolynomialFeatures(3)\npoly_features = pf.fit_transform(cars[[ 'productionDate', 'enginePower']])\npoly = pd.DataFrame(poly_features).drop([0,1,2,3,4,6,8], axis = 1)\npoly.columns = ['date_power5', 'date_power7', 'date_power9']\n\nfor col in list(poly.columns):\n    col_max = poly[col].max()    \n    poly[col] = poly[col].apply(lambda x: int(round(x/col_max*100000, 0)))\n    \ncars = pd.concat([cars, poly], axis=1)\nnum_f = num_f + list(poly.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим значимость полиномиальных признаков\nimp_num = Series(f_regression(cars[cars['sample'] == 1][num_f], y)[0], index = num_f)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Полиномиальные признаки показывают высокую значимость для целевой переменной, но  \nони очень сильно скоррелированны со своими предшественниками.\nПопробуем в дальнейшем запускать модели с ними и без них"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = cars[num_f].corr()\nplt.figure(figsize=(10, 6))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Итоги  \n В результате EDA и Feature Engineering добавлены:  \n  2 новых бинарных категориальных признака  \n  5 новых числовых, 3 из которых - полиномиальные  \n  2 новых числовых, переделанных из категориальных  \n  Выбросы не удалялись  \n  Датасет содержит 10 числовых и 11 категориальных признаков  \n  Сохранены сильно скоррелированные признаки  для отбора в ходе тестирования моделей"},{"metadata":{},"cell_type":"markdown","source":"# 5. Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Кодируем категориальные признаки\nfor col in cat_f:\n    cars[col] = cars[col].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_test = cars.copy()\nX_train_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разделяем обратно train и test\ntrain = X_train_test.query('sample == 1').drop(['sample'], axis=1)\ntest = X_train_test.query('sample == 0').drop(['sample'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Делим train для обучения и проверки моделей\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 1. \"Наивная\"  \nЭта модель будет предсказывать среднюю цену по модели двигателя (enginePower). \nC ней будем сравнивать другие модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train = X_train.copy()\ntmp_train['price'] = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Находим median по экземплярам enginePower в трейне и размечаем тест\npredict = X_test['enginePower'].map(tmp_train.groupby('enginePower')['price'].median())\n\n#оцениваем точность\nprint(f\"Точность наивной модели по метрике MAPE: {(mape(y_test, predict.values))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 2. CatBoost"},{"metadata":{},"cell_type":"markdown","source":"Из параметров CatBoost удалось подобрать оптимальный  learning_rate=0.25 при кол-ве итераций 10000.  \nbagging_temperature и random_strength на результат не повлияли.  \nОбъявление категориальных признаков(неоцифрованных) в пар-р cat_features тоже не улучшило результат "},{"metadata":{"trusted":true},"cell_type":"code","source":"ITERATIONS = 10000\nLR         = 0.25\nmodel = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = LR,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE']\n                         )\nmodel.fit(X_train, y_train,\n#         cat_features=cat_f,\n         eval_set=(X_test, y_test),\n         verbose_eval=100,\n         use_best_model=True,\n         plot=True\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(X_test)\n\n# оцениваем точность\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, predict))*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MAPE = 1.840%"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict_submission = model.predict(test)\n#sample_submission['price'] = predict_submission\n#sample_submission.to_csv('submission.csv', index=False)\n#sample_submission.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CatBoost + CV"},{"metadata":{},"cell_type":"markdown","source":"Применим кросс-валидацию с 5 фолдами"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cat_model(y_train, X_train, X_test, y_test):\n    model = CatBoostRegressor(iterations = 10000,\n                              learning_rate = 0.25,\n                              eval_metric='MAPE',\n                              custom_metric=['R2', 'MAE'],\n                              random_seed = RANDOM_SEED,)\n    model.fit(X_train, y_train,\n              #cat_features=cat_features_ids,\n              eval_set=(X_test, y_test),\n              verbose=False,\n              use_best_model=True,\n              plot=False)\n    \n    return(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.values\ny = y.values\nX_pred = test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"N_FOLDS = 5\nsubmissions = pd.DataFrame(0,columns=[\"sub_1\"], index=sample_submission.index) # куда пишем предикты\nscore_ls = []\nsplits = list(KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED).split(X,y))\n\nfor idx, (train_idx, test_idx) in tqdm(enumerate(splits), total=N_FOLDS,):\n    # use the indexes to extract the folds in the train and validation data\n    Xf_train, yf_train, Xf_test, yf_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n    # model for this fold\n    model = cat_model(yf_train, Xf_train, Xf_test, yf_test)\n    # score model on test\n    test_predict = model.predict(Xf_test)\n    test_score = mape(yf_test, test_predict)\n    score_ls.append(test_score)\n    print(f\"{idx+1} Fold Test MAPE: {mape(yf_test, test_predict)*100:0.3f}%\")\n    # submissions\n    submissions[f'sub_{idx+1}'] = model.predict(X_pred)\n    model.save_model(f'catboost_fold_{idx+1}.model')\n    \nprint(f'Mean Score: {np.mean(score_ls)*100:0.3f}%')\nprint(f'Std Score: {np.std(score_ls)*100:0.3f}%')\nprint(f'Max Score: {np.max(score_ls)*100:0.3f}%')\nprint(f'Min Score: {np.min(score_ls)*100:0.3f}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean MAPE: 2.019%"},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions['blend'] = (submissions.sum(axis=1))/len(submissions.columns)\nsample_submission['price'] = submissions['blend'].values\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CatBoost с кросс-валидацией дал лучший результат при submission: 12.05451"},{"metadata":{},"cell_type":"markdown","source":"Проверим теперь, как удаление признаков, сильно коррелирующих с другими, повлияет на MAPE."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_f = ['modelDate', 'date_power5', 'date_power7']\nfor col in corr_f:\n    tmp_train = train.drop([col], axis=1).copy()\n    X_train1, X_test1, y_train1, y_test1 = train_test_split(tmp_train, y,\n                                                        test_size=0.2, shuffle=True, random_state=42)\n    model = cat_model(y_train1, X_train1, X_test1, y_test1)\n    test_predict = model.predict(X_test1)\n    print(f\"{col} Test MAPE: {mape(y_test1, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Без отдельных признаков результат хуже(1.905%, 1.853%, 1.865%), чем базовый(1.840%). Не удаляем их."},{"metadata":{},"cell_type":"markdown","source":"# Model 3. Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"# A: пар-ры леса по умолчанию\nrf = RandomForestRegressor(random_state=42)\n\nrf.fit(X_train, y_train)\ntest_predict = rf.predict(X_test)\nprint(f\"Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"! RandomForestRegressor с параметрами по умолчанию показал MAPE = 1.756% -  пока лучший результат  \n  Попробуем подобрать значения для некоторых параметров с помощью RandomizedSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подобрать пар-ры леса не удалось из-за медленной скорости вычислений \n'''rf = RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(X_train, y_train)\n# Посмотрим, какие гиперпараметры нам предлагают как оптимальные:\nrf_random.best_params_'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# B: пар-ры леса случайные\nrf = RandomForestRegressor(\n n_estimators=300,\n min_samples_split=2,\n min_samples_leaf=1,\n max_features='sqrt',\n max_depth=77,\n bootstrap=True, \n random_state=42)\n\nrf.fit(X_train, y_train)\ntest_predict = rf.predict(X_test)\nprint(f\"Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MAPE = 1.647 - еще лучше  \nRandomForest выигрывает у  CatBoost по MAPE, но проигрывает при submission"},{"metadata":{},"cell_type":"markdown","source":"# Model 4. Bagging."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим сначала на точность одного дерева\ntree = DecisionTreeRegressor(max_features=int(X_train.shape[1]/3), max_depth=77)\ntree.fit(X_train, y_train)\ntest_predict = tree.predict(X_test)\nprint(f\"DecisionTreeRegressor Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь обернем деревья в BaggingRegressor\nbagging_trees = BaggingRegressor(tree)\nbagging_trees.fit(X_train, y_train)\ntest_predict = bagging_trees.predict(X_test)\nprint(f\"BaggingRegressor(DecisionTrees) Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bagging существенно улучшает качество дерева и дает очень неплохой MAPE = 1.757%"},{"metadata":{},"cell_type":"markdown","source":"# Model 5. GradientBoosting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оставляем только числовые признаки и сразу нормируем их для удобства\nnum_train = train.drop(cat_f, axis=1)\nscaler = StandardScaler()\nnum_train = pd.DataFrame(data=scaler.fit_transform(num_train), columns=num_train.columns)\nXn_train, Xn_test, yn_train, yn_test = train_test_split(num_train, y,\n                                                    test_size=0.2, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingRegressor(max_depth=7,n_estimators=1500,learning_rate=0.1,random_state=42)\ngb.fit(Xn_train, yn_train)\ntest_predict = gb.predict(Xn_test)\nprint(f\"GradientBoostingRegressor Test MAPE: {mape(yn_test, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пробуем также на полном наборе признаков.  \nGradientBoosting показывает результат MAPE = 1.865% на полном наборе и 2.354% без категориальных.  \nНа подбор пар-ров не хватает вычислит. ресурсов."},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingRegressor(max_depth=7,n_estimators=1500,learning_rate=0.1,random_state=42)\ngb.fit(X_train, y_train)\ntest_predict = gb.predict(X_test)\nprint(f\"GradientBoostingRegressor Test MAPE: {mape(y_test, test_predict)*100:0.3f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 6. Stacking."},{"metadata":{},"cell_type":"markdown","source":"Посмотрим, что даст стекинг с разбиением на фолды.  \nБудем использовать немного измененные функции из курса  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=5, shuffle=True, random_state=42)\n\ndef compute_metric(regr, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n    regr.fit(X_train, y_train)\n    y_test_pred = regr.predict(X_test)\n    return np.round(mape(y_test, y_test_pred)*100, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_meta_feature2(regr, X_train, X_test, y_train, cv, X_pred):    \n    \n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \n\n    splits = cv.split(X_train)\n    for train_fold_index, predict_fold_index in splits:\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n        \n        folded_regr = clone(regr)\n        folded_regr.fit(X_fold_train, y_fold_train)\n        \n        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\n    \n    meta_regr = clone(regr)\n    meta_regr.fit(X_train, y_train)\n    \n    X_meta_test = meta_regr.predict(X_test)\n    X_meta_pred = meta_regr.predict(X_pred)\n    \n    return X_meta_train, X_meta_test, X_meta_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_meta_features2(regr_s, X_train, X_test, y_train, cv, X_pred):\n   \n    features = [compute_meta_feature2(regr, X_train, X_test, y_train, cv, X_pred) for regr in tqdm(regr_s)]    \n    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\n    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\n    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\n    return stacked_features_train, stacked_features_test, stacked_features_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Передаем результаты работы набора из четырех регрессоров на 5ти фолдах каждый в мета-регрессор "},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features2([\n    RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \n                          max_features='sqrt',max_depth=77, bootstrap=True, random_state=42),\n    AdaBoostRegressor(random_state=42),\n    ExtraTreesRegressor(random_state=42),\n    RandomForestRegressor(random_state=42)], X_train, X_test, y_train, cv, X_pred)\n\nregr = RandomForestRegressor(\n n_estimators=300,\n min_samples_split=2,\n min_samples_leaf=1,\n max_features='sqrt',\n max_depth=77,\n bootstrap=True, \n random_state=42)\n\nprint(f'Stacking MAPE = {compute_metric(regr, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test, y_test=y_test)}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Стекинг дает MAPE = 1.654%.  \nПри submission результат стекинга очень близок к лучшему(CatBoost+CV): 12.49071"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict_submission = regr.predict(stacked_features_pred)#\n#sample_submission['price'] = predict_submission\n#sample_submission.to_csv('submission.csv', index=False)\n#sample_submission.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Итоги.  \n\nС авто.ру получено 280 тыс объявлений  \nПризнаки унифицированы с признаками из теста  \nПроведены анализ признаков, оценка их важности и скоррелированности  \nСозданы новые признаки и отобран набор для работы с алгоритмами  \nПротестировано 5 типов алгоритмов с регрессорами и 1 'наивный' для наглядности  \nЛучшую оценку MAPE = 1.647% показал RandomForestRegressor  \nЛучший submission выдал CatBoostRegressor с кросс-валидацией"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}